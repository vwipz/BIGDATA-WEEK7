---
title: "Homework Week 7: congressional speech"
date: "2024-05-06"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## R Markdown

This is an R Markdown document. Markdown is a simple formatting syntax for authoring HTML, PDF, and MS Word documents. For more details on using R Markdown see <http://rmarkdown.rstudio.com>.

When you click the **Knit** button a document will be generated that includes both content as well as the output of any embedded R code chunks within the document. You can embed an R code chunk like this:

```{r}
  library(textir)  # to get the data
  library(maptpx)  # for the topics function
  data(congress109)
```

# Question 1
**[1] Fit K-means to speech text for K in 5,10,15,20,25. Use BIC to choose the K and interpret the selected model.**

```{r}
  fs <- scale(as.matrix(congress109Counts/rowSums(congress109Counts)))
  kfit <- lapply(5*(1:5), function(k) kmeans(fs, k)) #K=5

  source("kIC.R") # Loads function to calculate BIC and AIC
  
  kaicc <- sapply(kfit, kIC)
  kbic <- sapply(kfit, kIC, "B")
  
  #view values for BIC and AIC to determine optimal K
  print(kaicc)
  print(kbic)
  
  par(mfrow=c(1,2))
  plot(5*(1:5), kaicc, xlab="K", ylab="IC",
  	bty="n", type="l", lwd=2,
  	main = "AIC")
  abline(v=which.min(kaicc)*5)
  plot(5*(1:5), kbic, xlab="K", ylab="IC",
  	bty="n", type="l", lwd=2, col=4,
  	main = "BIC")
  abline(v=which.min(kbic)*5,col=4)

  # Choosing optimal K based on lowest BIC values 
  kmfs <- kfit[[1]] #K=5 BIC value:540803
  # kmfs <- kfit[[2]] #K=10; BIC value: 557863
  # kmfs <- kfit[[3]] #K=15; BIC value: 574515
  # kmfs <- kfit[[4]] #K=20; BIC value: 594160
  # kmfs <- kfit[[5]] #K=25; BIC value: 613556

  print(apply(kmfs$centers,1,function(c) colnames(fs)[order(-c)[1:10]]))
  kmfs$size

```
We used BIC to determine the optimal number of clusters, The BIC values were lowest for K = 5 and showed a sharp increase for higher values. This indicates that five clusters optimize the balance between model complexity and fit, suggesting that additional clusters would lead to overfitting. Thus, K = 5 was selected, implying that the congressional speeches can be effectively categorized into five distinct thematic groups without unnecessary complexity.

There are differing clusters each run due to variability with the K-means algorithm. Here's an example of the clusters from one of our runs: 
Clusters: 
1: Biomedical and Ethical Issues, 17 speeches
2: Civil Rights and Social Justice, 178 speeches
3: Economic Policies and Social Security, 118 speeches
4: Governance and Urban Affairs, 48 speeches
5: National Security and Immigration, 168 speeches


# Question 2
**[2] Fit a topic model for the speech counts. Use Bayes factors to choose the number of topics, and interpret your chosen model.**

```{r}
  library(wordcloud)
  
  # Convert to slam matrix
  x <- as.simple_triplet_matrix(congress109Counts)
  
  # Topic modeling: choose the number of topics
  # Since BF is like exp(-BIC), we choose the biggest BF
  tpcs <- topics(x,K=2:25) # it chooses 12 topics
  num_topics <- tpcs$K #saves number of topics chosen
  
  # Generate summaries and print top terms for all topics
  summary(tpcs, n=10)
  for (k in 1:num_topics) {
    cat(paste("Top terms for Topic", k, ":\n"))
    print(rownames(tpcs$theta)[order(tpcs$theta[,k], decreasing=TRUE)[1:10]])
  }
  
  # ordered by simple in-topic prob
  print(rownames(tpcs$theta)[order(tpcs$theta[,1], decreasing=TRUE)[1:10]])
  print(rownames(tpcs$theta)[order(tpcs$theta[,2], decreasing=TRUE)[1:10]])
  
  #These ratios can be used to determine which issues skew more Rep and which skew more Dem
  DemO <- colMeans(tpcs$omega[congress109Ideology$party=="D",])
  RepO <- colMeans(tpcs$omega[congress109Ideology$party=="R",])
  sort(DemO/RepO) 
  
  # Loop throughs each topic and generate a word cloud
  # For the sake of simplifying for presentation, we're only using the top two topics for wordclouds so we are commenting the following code out. 
  # par(mfrow=c(4, 3))  
  # for (i in 1:num_topics) {
  #   wordcloud(names(tpcs$theta),
  #             freq=tpcs$theta[,i], min.freq=0.004,
  #             col=rainbow(12)[i],
  #             main=paste("Topic", i))
  # }
  
  par(mfrow=c(1,2))
  wordcloud(row.names(tpcs$theta), 
  	freq=tpcs$theta[,1], min.freq=0.004, col="navy") #changed min freq to exclude less frequent words
    title(main = "Topic 1 - Dem Focus", font.main = 1)
  wordcloud(row.names(tpcs$theta), 
  	freq=tpcs$theta[,2], min.freq=0.004, col="maroon")
    title(main = "Topic 2 - Rep Focus", font.main = 1)

```
Bayes factors chose 12 topics. 

Topic 2 appears to be more aligned with Democratic party priorities. Key terms include "hurricane.katrina", "million.american", "afford.colleg", "strong.support", "democrat.republican", "illegal.alien", "global.war.terrorism", "minimum.wage", "border.patrol", and "bring.troop". This topic seems to cover discussions related to disaster response (Hurricane Katrina), economic issues (affordable college, minimum wage), immigration (illegal aliens, border patrol), and foreign policy (global war on terrorism, bringing troops home).

Topic 2 appears to be more aligned with Republican party priorities. The top terms include "death.tax", "repeal.death.tax", "class.action", "action.lawsuit", "legal.system", "private.property", "medic.malpractice", "business.owner", "job.created", and "american.worker". This topic focuses on issues such as repealing the estate tax (death tax), tort reform (class action lawsuits), property rights, medical malpractice, supporting businesses and job creation, and protecting American workers.

The analysis also shows that Topics 1, 3, and 7 have a low Democratic to Republican ratio, indicating they are more associated with the Republican party, while Topics 2, 5, 6, and 12 have a high ratio, suggesting a stronger association with the Democratic party.


# Question 3
**[3] Connect the unsupervised clusters to partisanship. 
  > tabulate party membership by K-means cluster. Are there any non-partisan topics?
  > t topic regressions for each of party and repshare.
    Compare to regression onto phrase percentages:
    x<-100*congress109Counts/rowSums(congress109Counts)
    
```{r}

  library(gamlr)  # Ensure the library for regression analysis is loaded
  
  # Tabulate party membership by K-means cluster
  party_by_cluster <- tapply(congress109Ideology$party, kmfs$cluster, table)
  print(party_by_cluster)
  # Assessing non-partisan topics by looking at distribution of parties in clusters
  
  # Extracting significant terms from the largest cluster
  largest_cluster_terms <- colnames(fs)[order(-kmfs$centers[which.max(kmfs$size),])[1:10]]
  print(largest_cluster_terms)
  
  # Fit a logistic regression model to relate topics to party affiliation
  gop <- congress109Ideology[,"party"]=="R"  # Binary variable for Republican party
  partyreg <- gamlr(tpcs$omega, gop, family="binomial")
  print(exp(coef(partyreg)*0.1))  # Displaying exponentiated coefficients for interpretability
  
  # Fit a linear regression model to explore the relationship between topics and 'repshare'
  repreg <- gamlr(tpcs$omega, congress109Ideology[,"repshare"])
  print(coef(repreg)*0.1)  # Coefficients represent change in 'repshare' per 0.1 rise in topic weight
  
  # Comparison of topic-based and phrase percentage-based regression
  x <- 100*congress109Counts/rowSums(congress109Counts)  # Calculate phrase percentages
  regtopics_cv <- cv.gamlr(tpcs$omega, gop, family="binomial")
  regwords_cv <- cv.gamlr(x, gop, family="binomial")
  
  # Visualizing comparative performance of topic-based and phrase-based regression
  par(mfrow=c(1,2))
  plot(regtopics_cv, main="Topic Regression Performance")
  plot(regwords_cv, main="Phrase Count Regression Performance")
  
  # Displaying maximum out-of-sample R^2 to assess model performance
  max_oos_r2_topics <- max(1 - regtopics_cv$cvm / regtopics_cv$cvm[1])
  max_oos_r2_phrases <- max(1 - regwords_cv$cvm / regwords_cv$cvm[1])
  print(paste("Max OOS R^2 for topics: ", max_oos_r2_topics))
  print(paste("Max OOS R^2 for phrases: ", max_oos_r2_phrases))
```

Party Membership by Cluster: The largest cluster terms such as "death.tax" and "illegal.immigration" suggest a conservative bias, indicating these clusters may be predominantly associated with Republican party ideologies. Clusters 1, 3, 4, and 5 skew more Republican, and Cluster 2 skews Democratic.

Partisanship Association (Logistic Regression): Topics related to "border security" and "tax policies" show strong associations with the Republican party, with topics like "illegal immigration" having the highest odds ratio, indicating a strong likelihood of being discussed by Republicans. Certain topics show a negative association with the Republican party, which implies a Democratic preference, particularly for topics involving "civil rights" and "social security reform."

Representative Share Influence (Linear Regression): Positive coefficients indicate topics with increased emphasis in speeches associated with higher representative shares, suggesting these topics are of greater interest in Republican speeches. Topics with negative coefficients suggest a Democratic leaning, with topics such as "social reforms" and "civil rights" being more prevalent in speeches from Democratic representatives.

Topic vs. Phrase-Based Regression: Topic-based regression outperforms phrase-based regression, with a higher out-of-sample R^2 (approximately 0.545 for topics vs. 0.340 for phrases). This suggests that topic modeling more effectively captures the nuanced variations in speech that are indicative of partisanship, making it a more powerful tool for analyzing political discourse.
