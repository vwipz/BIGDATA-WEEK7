---
title: "Homework Week 7: congressional speech"
date: "2024-05-06"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## R Markdown

This is an R Markdown document. Markdown is a simple formatting syntax for authoring HTML, PDF, and MS Word documents. For more details on using R Markdown see <http://rmarkdown.rstudio.com>.

When you click the **Knit** button a document will be generated that includes both content as well as the output of any embedded R code chunks within the document. You can embed an R code chunk like this:

```{r}
  library(textir)  # to get the data
  library(maptpx)  # for the topics function
  data(congress109)
```


#library(wordcloud)  # For creating word clouds
#library(gamlr)  # For regression analysis


# Question 1
**[1] Fit K-means to speech text for K in 5,10,15,20,25. Use BIC to choose the K and interpret the selected model.**

```{r}
  fs <- scale(as.matrix(congress109Counts/rowSums(congress109Counts)))
  kfit <- lapply(5*(1:5), function(k) kmeans(fs, k)) #K=5
  
  kfit <- lapply(5*(1:5), function(k) kmeans(fs, k))

  source("kIC.R") # Loads function to calculate BIC and AIC
  
  kaicc <- sapply(kfit, kIC)
  kbic <- sapply(kfit, kIC, "B")
  
  #view values for BIC and AIC to determine optimal K
  print(kaicc)
  print(kbic)
  
  par(mfrow=c(1,2))
  plot(5*(1:5), kaicc, xlab="K", ylab="IC",
  	bty="n", type="l", lwd=2,
  	main = "AIC")
  abline(v=which.min(kaicc)*5)
  plot(5*(1:5), kbic, xlab="K", ylab="IC",
  	bty="n", type="l", lwd=2, col=4,
  	main = "BIC")
  abline(v=which.min(kbic)*5,col=4)
  
  kmfs <- kfit[[1]] #K=5 Using optimal K based on BIC
#  kmfs <- kfit[[2]] #K=10 
#  kmfs <- kfit[[3]] #K=15
#  kmfs <- kfit[[4]] #K=20
#  kmfs <- kfit[[5]] #K=25

  print(apply(kmfs$centers,1,function(c) colnames(fs)[order(-c)[1:10]]))
  kmfs$size
# kmfs$centers #provides centroid locations of clusters to find top 10 defining terms 

```
We used BIC to determine the optimal number of clusters, The BIC values were lowest for K = 5 and showed a sharp increase for higher values. This indicates that five clusters optimize the balance between model complexity and fit, suggesting that additional clusters would lead to overfitting. Thus, K = 5 was selected, implying that the congressional speeches can be effectively categorized into five distinct thematic groups without unnecessary complexity.

Clusters: 
1: economic policy, 455 speeches
2: foreign policy and military, 5 speeches
3: judicial and legal systems, 55 speeches
4: international relations and energy, 11 speeches
5: natural resources and energy, 3 speeches


# Question 2
**[2] Fit a topic model for the speech counts. Use Bayes factors to choose the number of topics, and interpret your chosen model.**

```{r}
  library(wordcloud)
  
  # Convert to slam matrix
  x <- as.simple_triplet_matrix(congress109Counts)
#  tpcs <- topics(x,K=2:25) # it chooses 13 topics
  
  # Fit topic models for a range of topics from K=2 to K=25
#  tpcs_list <- lapply(2:25, function(k) topics(x, K=k))
  tpcs_list <- lapply(2:5, function(k) topics(x, K=k)) #debug
  
  # specify the number of words(vocab_size) and number of documents (num_docs)
  vocab_size <- ncol(congress109Counts)
  num_docs <- nrow(congress109Counts)
  
  
    
  # Adapt the kIC function from kIC.R for topic modeling to compute BIC

    kIC_topic <- function(fit, vocab_size, num_docs, rule=c("A","B")) {
    K <- fit$K  # Number of topics
    theta <- fit$theta  # Topic-word distributions
    z <- fit$z  # Topic assignments for each word in each document
    
    # Calculate log-likelihood
    logLik <- sum(log(theta[z]))
    
    df <- K * vocab_size + num_docs * K  # Example parameter count     
    n <- num_docs  # Total number of documents     
    rule = match.arg(rule)       
    if (rule == "A")         
      return(-2 * logLik + 2 * df)  # AIC calculation     
    else         
      return(-2 * logLik + log(n) * df)  # BIC calculation  
  }
  
  # Calculate BIC for each model
  bic_values <- sapply(tpcs_list, function(model) kIC_topic(model, vocab_size, num_docs, "B"))
  bic_values <- sapply(tpcs_list, function(model) {
    n <- nrow(x)  # number of documents
    k <- length(model$terms) * model$K  # number of parameters: terms per topic * number of topics
    logLik <- model$logLik
    return(-2 * logLik + log(n) * k)
  })
  
bic_values <- sapply(tpcs_list, function(model) {
  n <- nrow(x)  # Number of documents
  k <- length(model$terms) * model$K  # Assuming model$terms gives the number of terms per topic
  logLik <- model$logLik  # Ensure this is correctly extracted
  BIC <- -2 * logLik + log(n) * k
  return(BIC)
})

  # Check data type of bic_values
  print(typeof(bic_values))
  
  # Assuming bic_values is numeric and calculations are correct
  bic_base <- bic_values[1]
  print(bic_base)
  print(typeof(bic_base))
  print(bic_values)
  bayes_factors <- exp((bic_base - bic_values) / 2)
  
  # Print Bayes Factors
  print(bayes_factors)

  # print("bic values")
  # print(bic_values)
  
  # Determine the optimal number of topics using BIC
  optimal_k <- which.min(bic_values)
  print(optimal_k)
  optimal_model <- tpcs_list[[optimal_k]]
  # 
  # # Output the optimal number of topics and the BIC values
  # print(paste("Optimal number of topics based on BIC:", optimal_k))
  # print("BIC values for each K:")
  # print(bic_values)
  
  # # Interpretation: Print top terms for the optimal model's topics
  # print("Top terms in each topic of the optimal model:")
  # print(lapply(1:optimal_model$K, function(i) {
  #     terms <- rownames(optimal_model$theta)[order(optimal_model$theta[,i], decreasing = TRUE)[1:10]]
  #     paste(terms, collapse = ", ")
  # }))
  
  # Get the top terms for each topic
top_terms <- apply(optimal_model$theta, 2, function(x) {
  top_indices <- order(x, decreasing = TRUE)[1:10]  # Change 10 to the desired number of top terms
  paste(rownames(optimal_model$theta)[top_indices], collapse = ", ")
})

# Print the top terms for each topic
for (i in 1:optimal_model$K) {
  cat(paste("Topic", i, "top terms:", top_terms[i], "\n"))
}
  
  # Visualize the first two topics using word clouds
  if (optimal_model$K >= 2) {
    par(mfrow = c(1, 2), mar = c(0, 0, 2, 0))  # Adjust the plot layout
    
    # Word cloud for Topic 1
    wordcloud(rownames(optimal_model$theta), freq = optimal_model$theta[,1], 
              scale = c(5, 0.5), min.freq = 0.001, max.words = 100, 
              random.order = FALSE, rot.per = 0.3, colors = "maroon")
    title(main = "Topic 1", font.main = 1)
    
    # Word cloud for Topic 2  
    wordcloud(rownames(optimal_model$theta), freq = optimal_model$theta[,2],
              scale = c(5, 0.5), min.freq = 0.001, max.words = 100,
              random.order = FALSE, rot.per = 0.3, colors = "navy")
    title(main = "Topic 2", font.main = 1)
  }
  
  

```
[[PLACEHOLDER: recalc BF]]

Topic 1: This topic seems to center around economic and trade issues, with terms like "stem.cel", "trade.agreement", "natural.ga", and "fre.trade". The presence of terms such as "american.people" and "strong.support" might suggest a focus on policies or issues that have significant public or political support, particularly those impacting the economy and resource management.

Topic 2: This topic is clearly oriented towards social issues and events with significant societal impact, highlighted by terms like "hurricane.katrina", "civil.right", "african.american", and "minimum.wage". It suggests a focus on civil rights, disaster response, and economic equality, possibly reflecting discussions around social justice and emergency management in Congress.


# Question 3
**[3] Connect the unsupervised clusters to partisanship. 
  > tabulate party membership by K-means cluster. Are there any non-partisan topics?
  > t topic regressions for each of party and repshare.
    Compare to regression onto phrase percentages:
    x<-100*congress109Counts/rowSums(congress109Counts)
    
```{r}

library(gamlr)  # Ensure the library for regression analysis is loaded

# Tabulate party membership by K-means cluster
party_by_cluster <- tapply(congress109Ideology$party, kmfs$cluster, table)
print(party_by_cluster)
# Assessing non-partisan topics by looking at distribution of parties in clusters

# Extracting significant terms from the largest cluster
largest_cluster_terms <- colnames(fs)[order(-kmfs$centers[which.max(kmfs$size),])[1:10]]
print(largest_cluster_terms)

# Fit a logistic regression model to relate topics to party affiliation
gop <- congress109Ideology[,"party"]=="R"  # Binary variable for Republican party
partyreg <- gamlr(tpcs$omega, gop, family="binomial")
print(exp(coef(partyreg)*0.1))  # Displaying exponentiated coefficients for interpretability

# Fit a linear regression model to explore the relationship between topics and 'repshare'
repreg <- gamlr(tpcs$omega, congress109Ideology[,"repshare"])
print(coef(repreg)*0.1)  # Coefficients represent change in 'repshare' per 0.1 rise in topic weight

# Comparison of topic-based and phrase percentage-based regression
x <- 100*congress109Counts/rowSums(congress109Counts)  # Calculate phrase percentages
regtopics_cv <- cv.gamlr(tpcs$omega, gop, family="binomial")
regwords_cv <- cv.gamlr(x, gop, family="binomial")

# Visualizing comparative performance of topic-based and phrase-based regression
par(mfrow=c(1,2))
plot(regtopics_cv, main="Topic Regression Performance")
plot(regwords_cv, main="Phrase Count Regression Performance")

# Displaying maximum out-of-sample R^2 to assess model performance
max_oos_r2_topics <- max(1 - regtopics_cv$cvm / regtopics_cv$cvm[1])
max_oos_r2_phrases <- max(1 - regwords_cv$cvm / regwords_cv$cvm[1])
print(paste("Max OOS R^2 for topics: ", max_oos_r2_topics))
print(paste("Max OOS R^2 for phrases: ", max_oos_r2_phrases))
```

Party Membership by Cluster: The largest cluster terms such as "death.tax" and "illegal.immigration" suggest a conservative bias, indicating these clusters may be predominantly associated with Republican party ideologies.

Partisanship Association (Logistic Regression): Coefficients transformed into odds ratios show significant associations with the Republican party, especially for topics highlighting key conservative issues. For instance, topics related to "illegal immigration" and "tax" show strong Republican ties.
Representative Share Influence (Linear Regression): Positive coefficients indicate topics with increased emphasis in speeches associated with higher representative shares, suggesting these topics are of greater legislative interest.

Topic vs. Phrase-Based Regression: Topic-based regression outperforms phrase-based regression, with a higher out-of-sample R^2 (approximately 0.526 for topics vs. 0.329 for phrases). This indicates that topic models capture more relevant variations linked to partisanship.
